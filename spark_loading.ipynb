{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Welcome to\n",
      "      ____              __\n",
      "     / __/__  ___ _____/ /__\n",
      "    _\\ \\/ _ \\/ _ `/ __/  '_/\n",
      "   /__ / .__/\\_,_/_/ /_/\\_\\   version 2.4.3\n",
      "      /_/\n",
      "\n",
      "Using Python version 3.7.1 (default, Dec 10 2018 22:54:23)\n",
      "SparkSession available as 'spark'.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "exec(open(os.path.join(os.environ[\"SPARK_HOME\"], 'python/pyspark/shell.py')).read())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Carregamento dos dados de treino"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = spark.read.csv(\"building_metadata.csv\", header=True, inferSchema=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = spark.read.csv(\"train.csv\", header=True, inferSchema=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = train.join(data, ['building_id'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+-----+-------------------+-------------+-------+-----------+-----------+----------+-----------+\n",
      "|building_id|meter|          timestamp|meter_reading|site_id|primary_use|square_feet|year_built|floor_count|\n",
      "+-----------+-----+-------------------+-------------+-------+-----------+-----------+----------+-----------+\n",
      "|          0|    0|2016-01-01 00:00:00|          0.0|      0|  Education|     7432.0|      2008|       null|\n",
      "|          1|    0|2016-01-01 00:00:00|          0.0|      0|  Education|     2720.0|      2004|       null|\n",
      "|          2|    0|2016-01-01 00:00:00|          0.0|      0|  Education|     5376.0|      1991|       null|\n",
      "|          3|    0|2016-01-01 00:00:00|          0.0|      0|  Education|    23685.0|      2002|       null|\n",
      "|          4|    0|2016-01-01 00:00:00|          0.0|      0|  Education|   116607.0|      1975|       null|\n",
      "+-----------+-----+-------------------+-------------+-------+-----------+-----------+----------+-----------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_train.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "weather_train = spark.read.csv(\"weather_train.csv\", header=True, inferSchema=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+-------------------+---------------+--------------+---------------+-----------------+------------------+--------------+----------+\n",
      "|site_id|          timestamp|air_temperature|cloud_coverage|dew_temperature|precip_depth_1_hr|sea_level_pressure|wind_direction|wind_speed|\n",
      "+-------+-------------------+---------------+--------------+---------------+-----------------+------------------+--------------+----------+\n",
      "|      0|2016-01-01 00:00:00|           25.0|           6.0|           20.0|             null|            1019.7|           0.0|       0.0|\n",
      "|      0|2016-01-01 01:00:00|           24.4|          null|           21.1|             -1.0|            1020.2|          70.0|       1.5|\n",
      "|      0|2016-01-01 02:00:00|           22.8|           2.0|           21.1|              0.0|            1020.2|           0.0|       0.0|\n",
      "|      0|2016-01-01 03:00:00|           21.1|           2.0|           20.6|              0.0|            1020.1|           0.0|       0.0|\n",
      "|      0|2016-01-01 04:00:00|           20.0|           2.0|           20.0|             -1.0|            1020.0|         250.0|       2.6|\n",
      "+-------+-------------------+---------------+--------------+---------------+-----------------+------------------+--------------+----------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "weather_train.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_train = df_train.join(weather_train, ['site_id', 'timestamp'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+-------------------+-----------+-----+-------------+-----------+-----------+----------+-----------+---------------+--------------+---------------+-----------------+------------------+--------------+----------+\n",
      "|site_id|          timestamp|building_id|meter|meter_reading|primary_use|square_feet|year_built|floor_count|air_temperature|cloud_coverage|dew_temperature|precip_depth_1_hr|sea_level_pressure|wind_direction|wind_speed|\n",
      "+-------+-------------------+-----------+-----+-------------+-----------+-----------+----------+-----------+---------------+--------------+---------------+-----------------+------------------+--------------+----------+\n",
      "|      0|2016-01-01 00:00:00|          0|    0|          0.0|  Education|     7432.0|      2008|       null|           25.0|           6.0|           20.0|             null|            1019.7|           0.0|       0.0|\n",
      "|      0|2016-01-01 00:00:00|          1|    0|          0.0|  Education|     2720.0|      2004|       null|           25.0|           6.0|           20.0|             null|            1019.7|           0.0|       0.0|\n",
      "|      0|2016-01-01 00:00:00|          2|    0|          0.0|  Education|     5376.0|      1991|       null|           25.0|           6.0|           20.0|             null|            1019.7|           0.0|       0.0|\n",
      "|      0|2016-01-01 00:00:00|          3|    0|          0.0|  Education|    23685.0|      2002|       null|           25.0|           6.0|           20.0|             null|            1019.7|           0.0|       0.0|\n",
      "|      0|2016-01-01 00:00:00|          4|    0|          0.0|  Education|   116607.0|      1975|       null|           25.0|           6.0|           20.0|             null|            1019.7|           0.0|       0.0|\n",
      "+-------+-------------------+-----------+-----+-------------+-----------+-----------+----------+-----------+---------------+--------------+---------------+-----------------+------------------+--------------+----------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "data_train.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- site_id: integer (nullable = true)\n",
      " |-- timestamp: timestamp (nullable = true)\n",
      " |-- building_id: integer (nullable = true)\n",
      " |-- meter: integer (nullable = true)\n",
      " |-- meter_reading: double (nullable = true)\n",
      " |-- primary_use: string (nullable = true)\n",
      " |-- square_feet: double (nullable = true)\n",
      " |-- year_built: integer (nullable = true)\n",
      " |-- floor_count: double (nullable = true)\n",
      " |-- air_temperature: double (nullable = true)\n",
      " |-- cloud_coverage: double (nullable = true)\n",
      " |-- dew_temperature: double (nullable = true)\n",
      " |-- precip_depth_1_hr: double (nullable = true)\n",
      " |-- sea_level_pressure: double (nullable = true)\n",
      " |-- wind_direction: double (nullable = true)\n",
      " |-- wind_speed: double (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "data_train.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyspark.sql.functions as SF\n",
    "from pyspark.sql.functions import udf\n",
    "import pyspark.sql.types as ST\n",
    "from pyspark.sql.functions import lit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_train.filter(SF.col('meter_reading').isNull()).count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Explorando os dados de treino"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16633726 3659684\n"
     ]
    }
   ],
   "source": [
    "# Verificando a quantidade de valores nulos nas colunas floor_count e precip_depth_1_hr\n",
    "\n",
    "a = data_train.filter(SF.col('floor_count').isNull()).count()\n",
    "b = data_train.filter(SF.col('precip_depth_1_hr').isNull()).count()\n",
    "\n",
    "print (a, b)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Conclusão da célula acima ^ : dropar coluna 'floor_count' pois existem mais missing values do que dados, apesr de o tamanho do prédio ser um parâmetro de grande influência, de acordo com estudos\n",
    "\n",
    "Tratar missing values da coluna precip_depth_1_hr com a média"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dropando coluna 'floor_count' => muitos valores nulos\n",
    "\n",
    "data_train = data_train.drop('floor_count')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Substituindo missing values pela média da coluna\n",
    "\n",
    "from pyspark.ml.feature import Imputer\n",
    "\n",
    "imputer = Imputer(\n",
    "    inputCols=['precip_depth_1_hr'], \n",
    "    outputCols=[\"precip_no_missing\"]\n",
    ")\n",
    "data_train = imputer.fit(data_train).transform(data_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- site_id: integer (nullable = true)\n",
      " |-- timestamp: timestamp (nullable = true)\n",
      " |-- building_id: integer (nullable = true)\n",
      " |-- meter: integer (nullable = true)\n",
      " |-- meter_reading: double (nullable = true)\n",
      " |-- primary_use: string (nullable = true)\n",
      " |-- square_feet: double (nullable = true)\n",
      " |-- year_built: integer (nullable = true)\n",
      " |-- air_temperature: double (nullable = true)\n",
      " |-- cloud_coverage: double (nullable = true)\n",
      " |-- dew_temperature: double (nullable = true)\n",
      " |-- precip_depth_1_hr: double (nullable = true)\n",
      " |-- sea_level_pressure: double (nullable = true)\n",
      " |-- wind_direction: double (nullable = true)\n",
      " |-- wind_speed: double (nullable = true)\n",
      " |-- precip_no_missing: double (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "data_train.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0.0243451719891813, -0.0034308352766083557, -0.004130718737031981, -0.003327480432342089)\n"
     ]
    }
   ],
   "source": [
    "#Verificando correlações entre algumas features e a variável alvo(meter reading)\n",
    "\n",
    "corr1 = data_train.corr('square_feet', 'meter_reading')\n",
    "corr2 = data_train.corr('floor_count', 'meter_reading')\n",
    "corr3 = data_train.corr('air_temperature', 'meter_reading')\n",
    "corr4 = data_train.corr('dew_temperature', 'meter_reading')\n",
    "\n",
    "a = (corr1, corr2, corr3, corr4)\n",
    "\n",
    "print(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+--------------------+\n",
      "|meter|  sum(meter_reading)|\n",
      "+-----+--------------------+\n",
      "|    1|2.6469138369947457E9|\n",
      "|    3|4.8424375217471313E8|\n",
      "|    2|3.758367124840034E10|\n",
      "|    0|2.0509979255654378E9|\n",
      "+-----+--------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Agrupando o consumo de energia por tipo de geração {0: electricity, 1: chilledwater, 2: steam, 3: hotwater}\n",
    "\n",
    "meter = data_train.groupBy(['meter']).agg(SF.sum('meter_reading')).alias('energy_type_consumption')\n",
    "meter.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+--------------------------+\n",
      "|meter|energy_type_avgconsumption|\n",
      "+-----+--------------------------+\n",
      "|    1|         636.1287307376127|\n",
      "|    3|         383.7977422611056|\n",
      "|    2|        13985.626222980976|\n",
      "|    0|        170.63067320028657|\n",
      "+-----+--------------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Média de consumo de energia por tipo de geração {0: electricity, 1: chilledwater, 2: steam, 3: hotwater}\n",
    "\n",
    "meter = data_train.groupBy(['meter']).agg(SF.mean('meter_reading').alias('energy_type_avgconsumption'))\n",
    "meter.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+--------------------+\n",
      "|         primary_use|  sum(meter_reading)|\n",
      "+--------------------+--------------------+\n",
      "|            Services|  3.97066208180799E8|\n",
      "|           Education|3.741569958853087E10|\n",
      "|Entertainment/pub...| 1.070394479290633E9|\n",
      "|             Parking| 3.621353672329998E7|\n",
      "|Manufacturing/ind...| 3.544375192059997E7|\n",
      "|Food sales and se...| 3.478257823299982E7|\n",
      "|          Healthcare| 2.941853399864968E8|\n",
      "|   Religious worship|   169620.2179000005|\n",
      "|              Office|2.3108906238607793E9|\n",
      "|  Technology/science|1.0557363489100015E7|\n",
      "|     Public services|4.7844049827199876E8|\n",
      "|               Other| 3.359877576220001E7|\n",
      "|             Utility|2.8291403059499964E7|\n",
      "| Lodging/residential| 5.982667954383855E8|\n",
      "|              Retail|1.5746474144500503E7|\n",
      "|   Warehouse/storage|   6079726.025100043|\n",
      "+--------------------+--------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Agrupando o consumo de energia por tipo de uso do prédio\n",
    "\n",
    "primary_use_consumption = data_train.groupBy(['primary_use']).agg(SF.sum('meter_reading'))\n",
    "primary_use_consumption.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+--------------------+\n",
      "|         primary_use|count(meter_reading)|\n",
      "+--------------------+--------------------+\n",
      "|            Services|               96510|\n",
      "|           Education|             8126540|\n",
      "|Entertainment/pub...|             2255388|\n",
      "|             Parking|              213827|\n",
      "|Manufacturing/ind...|              124488|\n",
      "|Food sales and se...|              114066|\n",
      "|          Healthcare|              398084|\n",
      "|   Religious worship|               31783|\n",
      "|              Office|             4380282|\n",
      "|  Technology/science|               76731|\n",
      "|     Public services|             1659241|\n",
      "|               Other|              242219|\n",
      "|             Utility|               55030|\n",
      "| Lodging/residential|             2131455|\n",
      "|              Retail|              112588|\n",
      "|   Warehouse/storage|              111864|\n",
      "+--------------------+--------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Quantidade de dados por tipo de uso primário\n",
    "\n",
    "primary_use_count = data_train.groupBy(['primary_use']).agg(SF.count('meter_reading'))\n",
    "primary_use_count.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+------------------+\n",
      "|         primary_use|avg(meter_reading)|\n",
      "+--------------------+------------------+\n",
      "|            Services| 4114.249385356948|\n",
      "|           Education| 4604.136519174319|\n",
      "|Entertainment/pub...|474.59438433237784|\n",
      "|             Parking|169.35904597314644|\n",
      "|Manufacturing/ind...| 284.7162129731377|\n",
      "|Food sales and se...| 304.9337947591729|\n",
      "|          Healthcare| 739.0031751753319|\n",
      "|   Religious worship| 5.336822134474421|\n",
      "|              Office| 527.5666324361717|\n",
      "|  Technology/science|137.58928580495515|\n",
      "|     Public services|  288.349009138515|\n",
      "|               Other|138.71238739405254|\n",
      "|             Utility| 514.1087235962196|\n",
      "| Lodging/residential|280.68469446382187|\n",
      "|              Retail|139.85925804260225|\n",
      "|   Warehouse/storage| 54.34926361564081|\n",
      "+--------------------+------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Média de consumo de energia por tipo de uso do prédio\n",
    "\n",
    "primary_use_count = data_train.groupBy(['primary_use']).agg(SF.mean('meter_reading'))\n",
    "primary_use_count.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+------------------+\n",
      "|summary|sea_level_pressure|\n",
      "+-------+------------------+\n",
      "|  count|          18988655|\n",
      "|   mean|1016.0857320604786|\n",
      "| stddev| 7.060842611881579|\n",
      "|    min|             968.2|\n",
      "|    max|            1045.5|\n",
      "+-------+------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Anlisando os dados da coluna sea_level_pressure (desconfio que todos os dados são iguais)\n",
    "\n",
    "data_train.describe('sea_level_pressure').show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Conclusão da célula acima: dropar a coluna sea_level_pressure pois a apmlitude de variação dos dados é muito baixa, provavelmente não causa tanta influência\n",
    "\n",
    "# Drop da coluna sea_level_pressure\n",
    "\n",
    "data_train = data_train.drop('sea_level_pressure')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, 0, 0, 12115911, 6163, 8735636, 9645, 1358553, 53181]\n"
     ]
    }
   ],
   "source": [
    "# Identificando a quantidade de missing values em cada uma das colunas\n",
    "\n",
    "columns = ['meter', 'primary_use', 'square_feet', 'year_built', 'air_temperature', 'cloud_coverage', 'dew_temperature', 'wind_direction', 'wind_speed']\n",
    "missing_number = []\n",
    "\n",
    "for count in columns:\n",
    "    x = data_train.filter(SF.col(count).isNull()).count()\n",
    "    missing_number.append(x)\n",
    "    \n",
    "print(missing_number)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Conclusões da célula acima ^:\n",
    "\n",
    "1. Somando os totais de valores nulos das colunas 'air_temperature', 'dew_temperature' e 'wind_speed' obtém-se um número de linhas com missing values que corresponde a, no máximo, 0.35% do tamanho da base. Por considerar esse valor irrisório, todas as linhas nulas dessas colunas vão ser dropadas\n",
    "\n",
    "\n",
    "2. Como o percentual de missing values na coluna é muito alto, as colunas 'year_built' e 'cloud_coverage' serão dropadas. Estudos mostram que a idade de um prédio influencia o seu consumo, por esse motivo, considerou-se melhor não inputar tantos dados de forma aleatória (ver http://www.irbnet.de/daten/iconda/CIB_DC25108.pdf)\n",
    "\n",
    "\n",
    "3. Substituir missing values pela média na coluna 'wind_direction'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dropando as linhas que contêm valores nulos nas colunas 'air_temperature', 'dew_temperature', 'wind_speed'\n",
    "\n",
    "data_train = data_train.na.drop(subset=['air_temperature', 'dew_temperature', 'wind_speed'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- site_id: integer (nullable = true)\n",
      " |-- timestamp: timestamp (nullable = true)\n",
      " |-- building_id: integer (nullable = true)\n",
      " |-- meter: integer (nullable = true)\n",
      " |-- meter_reading: double (nullable = true)\n",
      " |-- primary_use: string (nullable = true)\n",
      " |-- square_feet: double (nullable = true)\n",
      " |-- air_temperature: double (nullable = true)\n",
      " |-- dew_temperature: double (nullable = true)\n",
      " |-- precip_depth_1_hr: double (nullable = true)\n",
      " |-- wind_direction: double (nullable = true)\n",
      " |-- wind_speed: double (nullable = true)\n",
      " |-- precip_no_missing: double (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# dropando as colunas 'year_built' e 'cloud_coverage'\n",
    "\n",
    "data_train = data_train.drop('year_built', 'cloud_coverage')\n",
    "data_train.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# substituição de missing values usando o método imputer na coluna 'wind_direction'\n",
    "\n",
    "imputer = Imputer(\n",
    "    inputCols=['wind_direction'], \n",
    "    outputCols=[\"wind_direction_no_missing\"]\n",
    ")\n",
    "data_train = imputer.fit(data_train).transform(data_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+--------------------+\n",
      "|year_built|         consumption|\n",
      "+----------+--------------------+\n",
      "|      null|4.042068313658111...|\n",
      "|      2006| 1.661195065875976E8|\n",
      "|      2009| 9.758516870349969E7|\n",
      "|      1976|  8.67439377017974E7|\n",
      "|      2007| 8.163683573850028E7|\n",
      "|      1969| 7.244320173699997E7|\n",
      "|      1930|     6.89204354895E7|\n",
      "|      2010| 6.664581485770041E7|\n",
      "|      1989| 6.620940334480016E7|\n",
      "|      1952|6.4055442101500206E7|\n",
      "+----------+--------------------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Avaliando como a idade pode interferir no consumo de energia do prédio\n",
    "data_train.groupBy(['year_built']).agg(SF.sum('meter_reading').alias('consumption')).sort(SF.col('consumption').desc()).show(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(-0.1425580577090447, 0.06028352081244824, -0.08327778700727852, 0.06028352081244824, -0.010001658917668502)\n"
     ]
    }
   ],
   "source": [
    "#Avaliando as correlações entre as variáveis de tempo\n",
    "\n",
    "corr1 = data_train.corr('wind_speed', 'dew_temperature')\n",
    "corr2 = data_train.corr('dew_temperature', 'cloud_coverage')\n",
    "corr3 = data_train.corr('air_temperature', 'wind_speed')\n",
    "corr4 = data_train.corr('dew_temperature', 'cloud_coverage')\n",
    "corr5 = data_train.corr('precip_depth_1_hr', 'cloud_coverage')\n",
    "\n",
    "a = (corr1, corr2, corr3, corr4, corr5)\n",
    "\n",
    "print(a)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data preparation - base de treino"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- site_id: integer (nullable = true)\n",
      " |-- timestamp: timestamp (nullable = true)\n",
      " |-- building_id: integer (nullable = true)\n",
      " |-- meter: integer (nullable = true)\n",
      " |-- meter_reading: double (nullable = true)\n",
      " |-- primary_use: string (nullable = true)\n",
      " |-- square_feet: double (nullable = true)\n",
      " |-- air_temperature: double (nullable = true)\n",
      " |-- dew_temperature: double (nullable = true)\n",
      " |-- precip_depth_1_hr: double (nullable = true)\n",
      " |-- wind_direction: double (nullable = true)\n",
      " |-- wind_speed: double (nullable = true)\n",
      " |-- precip_no_missing: double (nullable = true)\n",
      " |-- wind_direction_no_missing: double (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "data_train.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dropando as colunas que foram tratadas com o metodo inputer\n",
    "\n",
    "data_train = data_train.drop('precip_depth_1_hr', 'wind_direction')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+-------------------+-----------+-----+-------------+-----------+-----------+---------------+---------------+----------+------------------+-------------------------+\n",
      "|site_id|          timestamp|building_id|meter|meter_reading|primary_use|square_feet|air_temperature|dew_temperature|wind_speed| precip_no_missing|wind_direction_no_missing|\n",
      "+-------+-------------------+-----------+-----+-------------+-----------+-----------+---------------+---------------+----------+------------------+-------------------------+\n",
      "|      0|2016-01-01 00:00:00|          0|    0|          0.0|  Education|     7432.0|           25.0|           20.0|       0.0|0.7962514234616596|                      0.0|\n",
      "|      0|2016-01-01 00:00:00|          1|    0|          0.0|  Education|     2720.0|           25.0|           20.0|       0.0|0.7962514234616596|                      0.0|\n",
      "|      0|2016-01-01 00:00:00|          2|    0|          0.0|  Education|     5376.0|           25.0|           20.0|       0.0|0.7962514234616596|                      0.0|\n",
      "|      0|2016-01-01 00:00:00|          3|    0|          0.0|  Education|    23685.0|           25.0|           20.0|       0.0|0.7962514234616596|                      0.0|\n",
      "|      0|2016-01-01 00:00:00|          4|    0|          0.0|  Education|   116607.0|           25.0|           20.0|       0.0|0.7962514234616596|                      0.0|\n",
      "+-------+-------------------+-----------+-----+-------------+-----------+-----------+---------------+---------------+----------+------------------+-------------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "data_train.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- site_id: integer (nullable = true)\n",
      " |-- timestamp: timestamp (nullable = true)\n",
      " |-- building_id: integer (nullable = true)\n",
      " |-- meter: integer (nullable = true)\n",
      " |-- meter_reading: double (nullable = true)\n",
      " |-- primary_use: string (nullable = true)\n",
      " |-- square_feet: double (nullable = true)\n",
      " |-- air_temperature: double (nullable = true)\n",
      " |-- dew_temperature: double (nullable = true)\n",
      " |-- wind_speed: double (nullable = true)\n",
      " |-- precip_no_missing: double (nullable = true)\n",
      " |-- wind_direction_no_missing: double (nullable = true)\n",
      " |-- timestamp_unix: long (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# transformando a coluna de tempo em timestamp\n",
    "\n",
    "data_train = data_train.withColumn('timestamp_unix', SF.unix_timestamp('timestamp'))\n",
    "data_train.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dropando a coluna que foi transformada\n",
    "\n",
    "data_train = data_train.drop('timestamp')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- site_id: integer (nullable = true)\n",
      " |-- building_id: integer (nullable = true)\n",
      " |-- meter: integer (nullable = true)\n",
      " |-- meter_reading: double (nullable = true)\n",
      " |-- primary_use: string (nullable = true)\n",
      " |-- square_feet: double (nullable = true)\n",
      " |-- air_temperature: double (nullable = true)\n",
      " |-- dew_temperature: double (nullable = true)\n",
      " |-- wind_speed: double (nullable = true)\n",
      " |-- precip_no_missing: double (nullable = true)\n",
      " |-- wind_direction_no_missing: double (nullable = true)\n",
      " |-- timestamp_unix: long (nullable = true)\n",
      " |-- primary_use_index: double (nullable = false)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# a coluna 'primary_use' precisa de um string index\n",
    "\n",
    "from pyspark.ml.feature import StringIndexer\n",
    "\n",
    "indexer = StringIndexer(inputCol=\"primary_use\", outputCol=\"primary_use_index\")\n",
    "indexed_train = indexer.fit(data_train).transform(data_train)\n",
    "indexed_train.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- site_id: integer (nullable = true)\n",
      " |-- building_id: integer (nullable = true)\n",
      " |-- meter: integer (nullable = true)\n",
      " |-- meter_reading: double (nullable = true)\n",
      " |-- primary_use: string (nullable = true)\n",
      " |-- square_feet: double (nullable = true)\n",
      " |-- air_temperature: double (nullable = true)\n",
      " |-- dew_temperature: double (nullable = true)\n",
      " |-- wind_speed: double (nullable = true)\n",
      " |-- precip_no_missing: double (nullable = true)\n",
      " |-- wind_direction_no_missing: double (nullable = true)\n",
      " |-- timestamp_unix: long (nullable = true)\n",
      " |-- primary_use_index: double (nullable = false)\n",
      " |-- meter_vec: vector (nullable = true)\n",
      " |-- primary_use_vec: vector (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# as colunas 'meter'e 'primary_use_index' precisam de um encode\n",
    "\n",
    "from pyspark.ml.feature import OneHotEncoderEstimator\n",
    "\n",
    "encoder = OneHotEncoderEstimator(inputCols=[\"meter\", \"primary_use_index\"], outputCols=[\"meter_vec\", \"primary_use_vec\"])\n",
    "model = encoder.fit(indexed_train) # dataframe gerado com StringIndexer\n",
    "encoded_train = model.transform(indexed_train)\n",
    "encoded_train.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dropando as colunas que passaram pelo encoded\n",
    "\n",
    "encoded_train = encoded_train.drop('meter', 'primary_use', 'primary_use_index')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- site_id: integer (nullable = true)\n",
      " |-- building_id: integer (nullable = true)\n",
      " |-- meter_reading: double (nullable = true)\n",
      " |-- square_feet: double (nullable = true)\n",
      " |-- air_temperature: double (nullable = true)\n",
      " |-- dew_temperature: double (nullable = true)\n",
      " |-- wind_speed: double (nullable = true)\n",
      " |-- precip_no_missing: double (nullable = true)\n",
      " |-- wind_direction_no_missing: double (nullable = true)\n",
      " |-- timestamp_unix: long (nullable = true)\n",
      " |-- meter_vec: vector (nullable = true)\n",
      " |-- primary_use_vec: vector (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "encoded_train.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 'site_id' e 'building_id' não servem em nada para o modelo\n",
    "\n",
    "encoded_train = encoded_train.drop('site_id', 'building_id')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- meter_reading: double (nullable = true)\n",
      " |-- square_feet: double (nullable = true)\n",
      " |-- air_temperature: double (nullable = true)\n",
      " |-- dew_temperature: double (nullable = true)\n",
      " |-- wind_speed: double (nullable = true)\n",
      " |-- precip_no_missing: double (nullable = true)\n",
      " |-- wind_direction_no_missing: double (nullable = true)\n",
      " |-- timestamp_unix: long (nullable = true)\n",
      " |-- meter_vec: vector (nullable = true)\n",
      " |-- primary_use_vec: vector (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "encoded_train.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+-------------+\n",
      "|            features|meter_reading|\n",
      "+--------------------+-------------+\n",
      "|(25,[0,1,2,4,6,7,...|          0.0|\n",
      "|(25,[0,1,2,4,6,7,...|          0.0|\n",
      "|(25,[0,1,2,4,6,7,...|          0.0|\n",
      "+--------------------+-------------+\n",
      "only showing top 3 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# criando o vetor de features\n",
    "\n",
    "from pyspark.ml.feature import VectorAssembler\n",
    "\n",
    "vectorAssembler = VectorAssembler(inputCols = ['square_feet', 'air_temperature', 'dew_temperature', 'wind_speed', 'precip_no_missing', 'wind_direction_no_missing', 'timestamp_unix', 'meter_vec', 'primary_use_vec'], outputCol = 'features')\n",
    "train_base = vectorAssembler.transform(encoded_train)\n",
    "train_base = train_base.select(['features', 'meter_reading'])\n",
    "train_base.show(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+-----+\n",
      "|            features|label|\n",
      "+--------------------+-----+\n",
      "|(25,[0,1,2,4,6,7,...|  0.0|\n",
      "|(25,[0,1,2,4,6,7,...|  0.0|\n",
      "|(25,[0,1,2,4,6,7,...|  0.0|\n",
      "+--------------------+-----+\n",
      "only showing top 3 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "train_base = train_base.withColumnRenamed('meter_reading', 'label')\n",
    "train_base.show(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data preparation - base de testes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test = spark.read.csv(\"test.csv\", header=True, inferSchema=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test = df_test.join(data, ['building_id'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "weather_test = spark.read.csv('weather_test.csv', header=True, inferSchema=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_test = df_test.join(weather_test, ['site_id', 'timestamp'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dropando as colunas que foram dropadas na base de treino\n",
    "\n",
    "data_test = data_test.drop('floor_count', 'sea_level_pressure', 'year_built', 'cloud_coverage')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- site_id: integer (nullable = true)\n",
      " |-- timestamp: timestamp (nullable = true)\n",
      " |-- building_id: integer (nullable = true)\n",
      " |-- row_id: integer (nullable = true)\n",
      " |-- meter: integer (nullable = true)\n",
      " |-- primary_use: string (nullable = true)\n",
      " |-- square_feet: double (nullable = true)\n",
      " |-- air_temperature: double (nullable = true)\n",
      " |-- dew_temperature: double (nullable = true)\n",
      " |-- precip_depth_1_hr: double (nullable = true)\n",
      " |-- wind_direction: double (nullable = true)\n",
      " |-- wind_speed: double (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "data_test.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, 0, 0, 22872, 61770, 7604260, 2780535, 103060]\n"
     ]
    }
   ],
   "source": [
    "# Identificando a quantidade de missing values em cada uma das colunas\n",
    "\n",
    "columns = ['meter', 'primary_use', 'square_feet', 'air_temperature', 'dew_temperature', 'precip_depth_1_hr', 'wind_direction', 'wind_speed']\n",
    "missing_number = []\n",
    "\n",
    "for count in columns:\n",
    "    x = data_test.filter(SF.col(count).isNull()).count()\n",
    "    missing_number.append(x)\n",
    "    \n",
    "print(missing_number)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Conclusão da célula acima:\n",
    "\n",
    "1. Aplicar o método Imputer para 'preecip_depth_1_hr' e 'wind_direction'\n",
    "\n",
    "2. Dropar as linhas nulas de 'air_temperature', 'dew_temperature' e 'wind_speed' "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# substituição de missing values usando o método imputer\n",
    "\n",
    "imputer = Imputer(\n",
    "    inputCols=['precip_depth_1_hr', 'wind_direction'], \n",
    "    outputCols=['precip_no_missing','wind_direction_no_missing']\n",
    ")\n",
    "data_test = imputer.fit(data_test).transform(data_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dropando as linhas que contêm valores nulos nas colunas 'air_temperature', 'dew_temperature', 'wind_speed'\n",
    "\n",
    "data_test = data_test.na.drop(subset=['air_temperature', 'dew_temperature', 'wind_speed'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- site_id: integer (nullable = true)\n",
      " |-- timestamp: timestamp (nullable = true)\n",
      " |-- building_id: integer (nullable = true)\n",
      " |-- row_id: integer (nullable = true)\n",
      " |-- meter: integer (nullable = true)\n",
      " |-- primary_use: string (nullable = true)\n",
      " |-- square_feet: double (nullable = true)\n",
      " |-- air_temperature: double (nullable = true)\n",
      " |-- dew_temperature: double (nullable = true)\n",
      " |-- precip_depth_1_hr: double (nullable = true)\n",
      " |-- wind_direction: double (nullable = true)\n",
      " |-- wind_speed: double (nullable = true)\n",
      " |-- precip_no_missing: double (nullable = true)\n",
      " |-- wind_direction_no_missing: double (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "data_test.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- site_id: integer (nullable = true)\n",
      " |-- timestamp: timestamp (nullable = true)\n",
      " |-- building_id: integer (nullable = true)\n",
      " |-- row_id: integer (nullable = true)\n",
      " |-- meter: integer (nullable = true)\n",
      " |-- primary_use: string (nullable = true)\n",
      " |-- square_feet: double (nullable = true)\n",
      " |-- air_temperature: double (nullable = true)\n",
      " |-- dew_temperature: double (nullable = true)\n",
      " |-- precip_depth_1_hr: double (nullable = true)\n",
      " |-- wind_direction: double (nullable = true)\n",
      " |-- wind_speed: double (nullable = true)\n",
      " |-- precip_no_missing: double (nullable = true)\n",
      " |-- wind_direction_no_missing: double (nullable = true)\n",
      " |-- primary_use_index: double (nullable = false)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# a coluna 'primary_use' precisa de um string index\n",
    "\n",
    "indxr = StringIndexer(inputCol=\"primary_use\", outputCol=\"primary_use_index\")\n",
    "indexed_test = indxr.fit(data_test).transform(data_test)\n",
    "indexed_test.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- site_id: integer (nullable = true)\n",
      " |-- timestamp: timestamp (nullable = true)\n",
      " |-- building_id: integer (nullable = true)\n",
      " |-- row_id: integer (nullable = true)\n",
      " |-- meter: integer (nullable = true)\n",
      " |-- primary_use: string (nullable = true)\n",
      " |-- square_feet: double (nullable = true)\n",
      " |-- air_temperature: double (nullable = true)\n",
      " |-- dew_temperature: double (nullable = true)\n",
      " |-- precip_depth_1_hr: double (nullable = true)\n",
      " |-- wind_direction: double (nullable = true)\n",
      " |-- wind_speed: double (nullable = true)\n",
      " |-- precip_no_missing: double (nullable = true)\n",
      " |-- wind_direction_no_missing: double (nullable = true)\n",
      " |-- primary_use_index: double (nullable = false)\n",
      " |-- meter_vec: vector (nullable = true)\n",
      " |-- primary_use_vec: vector (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# as colunas 'meter'e 'primary_use_index' precisam de um encode\n",
    "\n",
    "encdr = OneHotEncoderEstimator(inputCols=[\"meter\", \"primary_use_index\"], outputCols=[\"meter_vec\", \"primary_use_vec\"])\n",
    "model_test = encdr.fit(indexed_test) # dataframe gerado com StringIndexer\n",
    "encoded_test = model.transform(indexed_test)\n",
    "encoded_test.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- site_id: integer (nullable = true)\n",
      " |-- timestamp: timestamp (nullable = true)\n",
      " |-- building_id: integer (nullable = true)\n",
      " |-- row_id: integer (nullable = true)\n",
      " |-- square_feet: double (nullable = true)\n",
      " |-- air_temperature: double (nullable = true)\n",
      " |-- dew_temperature: double (nullable = true)\n",
      " |-- precip_depth_1_hr: double (nullable = true)\n",
      " |-- wind_direction: double (nullable = true)\n",
      " |-- wind_speed: double (nullable = true)\n",
      " |-- precip_no_missing: double (nullable = true)\n",
      " |-- wind_direction_no_missing: double (nullable = true)\n",
      " |-- meter_vec: vector (nullable = true)\n",
      " |-- primary_use_vec: vector (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# dropando as colunas que passaram pelo encoded\n",
    "\n",
    "encoded_test = encoded_test.drop('meter', 'primary_use', 'primary_use_index')\n",
    "encoded_test.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dropando as colunas que foram tratadas com o metodo inputer\n",
    "\n",
    "encoded_test = encoded_test.drop('precip_depth_1_hr', 'wind_direction')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- site_id: integer (nullable = true)\n",
      " |-- building_id: integer (nullable = true)\n",
      " |-- row_id: integer (nullable = true)\n",
      " |-- square_feet: double (nullable = true)\n",
      " |-- air_temperature: double (nullable = true)\n",
      " |-- dew_temperature: double (nullable = true)\n",
      " |-- wind_speed: double (nullable = true)\n",
      " |-- precip_no_missing: double (nullable = true)\n",
      " |-- wind_direction_no_missing: double (nullable = true)\n",
      " |-- meter_vec: vector (nullable = true)\n",
      " |-- primary_use_vec: vector (nullable = true)\n",
      " |-- timestamp_unix: long (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# transformando a coluna de tempo em timestamp\n",
    "\n",
    "encoded_test = encoded_test.withColumn('timestamp_unix', SF.unix_timestamp('timestamp'))\n",
    "\n",
    "# dropando a coluna que foi transformada\n",
    "\n",
    "encoded_test = encoded_test.drop('timestamp')\n",
    "\n",
    "encoded_test.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- square_feet: double (nullable = true)\n",
      " |-- air_temperature: double (nullable = true)\n",
      " |-- dew_temperature: double (nullable = true)\n",
      " |-- wind_speed: double (nullable = true)\n",
      " |-- precip_no_missing: double (nullable = true)\n",
      " |-- wind_direction_no_missing: double (nullable = true)\n",
      " |-- meter_vec: vector (nullable = true)\n",
      " |-- primary_use_vec: vector (nullable = true)\n",
      " |-- timestamp_unix: long (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# as colunas 'site_id', 'building_id' e 'row_id' não servem em nada para o modelo\n",
    "\n",
    "encoded_test = encoded_test.drop('site_id', 'building_id', 'row_id')\n",
    "encoded_test.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- square_feet: double (nullable = true)\n",
      " |-- air_temperature: double (nullable = true)\n",
      " |-- dew_temperature: double (nullable = true)\n",
      " |-- wind_speed: double (nullable = true)\n",
      " |-- precip_no_missing: double (nullable = true)\n",
      " |-- wind_direction_no_missing: double (nullable = true)\n",
      " |-- timestamp_unix: long (nullable = true)\n",
      " |-- meter_vec: vector (nullable = true)\n",
      " |-- primary_use_vec: vector (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# reordenando as colunas para ficar na mesma ordem do dataframe de treino\n",
    "\n",
    "encoded_test = encoded_test.select('square_feet', 'air_temperature', 'dew_temperature', 'wind_speed', 'precip_no_missing', 'wind_direction_no_missing', 'timestamp_unix', 'meter_vec', 'primary_use_vec')\n",
    "encoded_test.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+\n",
      "|            features|\n",
      "+--------------------+\n",
      "|(25,[0,1,2,3,5,6,...|\n",
      "|(25,[0,1,2,3,5,6,...|\n",
      "|(25,[0,1,2,3,5,6,...|\n",
      "+--------------------+\n",
      "only showing top 3 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# criando o vetor de features\n",
    "\n",
    "vectorAssembler = VectorAssembler(inputCols = ['square_feet', 'air_temperature', 'dew_temperature', 'wind_speed', 'precip_no_missing', 'wind_direction_no_missing', 'timestamp_unix', 'meter_vec', 'primary_use_vec'], outputCol = 'features')\n",
    "test_base = vectorAssembler.transform(encoded_test)\n",
    "test_base = test_base.select(['features'])\n",
    "test_base.show(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Criando o modelo de regressão múltipla"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.regression import LinearRegression\n",
    "\n",
    "# Cria o modelo\n",
    "linearRegression = LinearRegression(featuresCol='features', labelCol='label')\n",
    "\n",
    "# Treina o modelo com a base de treinamento (data frame formatado)\n",
    "lrModel = linearRegression.fit(train_base)\n",
    "\n",
    "# Aplica o modelo treinado para predizer a saída (label) na base de testes\n",
    "predictions = lrModel.transform(test_base)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+-------------------+\n",
      "|            features|         prediction|\n",
      "+--------------------+-------------------+\n",
      "|(25,[0,1,2,3,5,6,...|-2072.7602130970918|\n",
      "|(25,[0,1,2,3,5,6,...|-2205.1804752209573|\n",
      "|(25,[0,1,2,3,5,6,...|-2130.5395125297364|\n",
      "|(25,[0,1,2,3,5,6,...|-1616.0058581948688|\n",
      "|(25,[0,1,2,3,5,6,...|  995.3599306579272|\n",
      "|(25,[0,1,2,3,5,6,...|-2056.7978385456663|\n",
      "|(25,[0,1,2,3,5,6,...| -5601.790773884102|\n",
      "|(25,[0,1,2,3,5,6,...| 1120.8950136178755|\n",
      "|(25,[0,1,2,3,5,6,...|  793.9762024768861|\n",
      "|(25,[0,1,2,3,5,6,...| -572.7185468437383|\n",
      "|(25,[0,1,2,3,5,6,...|  -5305.65946889497|\n",
      "|(25,[0,1,2,3,5,6,...| -5632.578280035959|\n",
      "|(25,[0,1,2,3,5,6,...|  4741.997022825672|\n",
      "|(25,[0,1,2,3,5,6,...|  -902.532680181117|\n",
      "|(25,[0,1,2,3,5,6,...| -5343.975942660763|\n",
      "|(25,[0,1,2,3,5,6,...|  511.2334757326462|\n",
      "|(25,[0,1,2,3,5,6,...| 184.31466459165676|\n",
      "|(25,[0,1,2,3,5,6,...|  142.2440780912002|\n",
      "|(25,[0,1,2,3,5,6,...| -184.6747330497892|\n",
      "|(25,[0,1,2,3,5,6,...|-3705.0098785322043|\n",
      "+--------------------+-------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "predictions.show(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE: 153637.048438\n",
      "r2: 0.001636\n"
     ]
    }
   ],
   "source": [
    "# avaliando o erro médio quadrático e o r2\n",
    "\n",
    "trainingSummary = lrModel.summary\n",
    "print(\"RMSE: %f\" % trainingSummary.rootMeanSquaredError)\n",
    "print(\"r2: %f\" % trainingSummary.r2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_base.printSchema()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
